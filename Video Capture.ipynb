{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0] global ../modules/videoio/src/cap_gstreamer.cpp (935) open OpenCV | GStreamer warning: Cannot query video position: status=0, value=-1, duration=-1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# vid = cv2.VideoCapture('/home/saddy/Downloads/orange.mp4')\n",
    "\n",
    "vid = cv2.VideoCapture(0)\n",
    "\n",
    "while(True):\n",
    "    ret, frame = vid.read()\n",
    "\n",
    "      # ............................\n",
    "    frame = cv2.resize(frame, (800, 600))\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    lower_bound = np.array([10, 80, 80])\n",
    "    upper_bound = np.array([25, 255, 255])\n",
    "\n",
    "      # find the colors within the boundaries\n",
    "    mask = cv2.inRange(hsv, lower_bound, upper_bound)\n",
    "\n",
    "    # define kernel size\n",
    "    kernel = np.ones((8, 8), np.uint8)\n",
    "\n",
    "      # Remove unnecessary noise from mask\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_ELLIPSE, kernel)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_ELLIPSE, kernel)\n",
    "\n",
    "       # Segment only the detected region(this is used to find green reasion in image)\n",
    "    segmented_img = cv2.bitwise_and(frame, frame, mask=mask)\n",
    "\n",
    "       # Find contours from the mask\n",
    "    contours, hierarchy = cv2.findContours(\n",
    "    mask.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    output = cv2.drawContours(frame, contours, -1, (0, 0, 255), 5)\n",
    "       # plt.imshow(image)\n",
    "      # plt.show()\n",
    "      # cv2.imshow('frame',image)\n",
    "     # cv2.imshow('mask',mask)\n",
    "    cv2.imshow('Yellow detected', output)\n",
    "\n",
    "    # cv2.imshow('Segmented', segmented_img)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    \n",
    "\n",
    "\n",
    "# After the loop release the cap object\n",
    "vid.release()\n",
    "# Destroy all the windows\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
